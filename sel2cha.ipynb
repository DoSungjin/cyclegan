{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pint7KYSOLrN"
      },
      "source": [
        "## 0. 기본 작업"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HL7sjN-lp12",
        "outputId": "8b9521cd-6a92-4082-ec66-f5e5c09dfba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브 마운트 및 경로 설정\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMDuYwIBlpa3",
        "outputId": "efe31288-3f23-4d71-ecd4-6b40dff488a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/python/data/Dataset\n"
          ]
        }
      ],
      "source": [
        "cd gdrive/MyDrive/python/data/'Dataset'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWiS4PWAD3VA"
      },
      "source": [
        " ## 1. 필요 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgHMZv6QIXDB"
      },
      "outputs": [],
      "source": [
        "# 기본 라이브러리\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import itertools\n",
        "import glob\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# 데이터 처리 관련 라이브러리\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# 학습 관련 라이브러리\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8NuFxHucVY6"
      },
      "source": [
        "## 2. 클래스 및 함수 정의"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBTEQsGiD3VC"
      },
      "source": [
        "#### 1. DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V3Jc_iFD3VC"
      },
      "outputs": [],
      "source": [
        "# 흑백사진 RGB 변환 함수\n",
        "\n",
        "def to_rgb(image):\n",
        "    rgb_image = Image.new(\"RGB\", image.size)\n",
        "    rgb_image.paste(image)\n",
        "    return rgb_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjBBLhG8D3VC"
      },
      "outputs": [],
      "source": [
        "# Train / Test 모드에 따라 DataSet 불러오는 class 정의\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_=None, unaligned=False, mode=\"train\"):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        self.unaligned = unaligned\n",
        "        if mode==\"train\":\n",
        "            self.files_A = sorted(glob.glob(os.path.join(root, \"trainA\") + \"/*.*\"))\n",
        "            self.files_B = sorted(glob.glob(os.path.join(root, \"trainB\") + \"/*.*\"))\n",
        "        else:\n",
        "            self.files_A = sorted(glob.glob(os.path.join(root, \"testA\") + \"/*.*\"))\n",
        "            self.files_B = sorted(glob.glob(os.path.join(root, \"testB\") + \"/*.*\"))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_A = Image.open(self.files_A[index % len(self.files_A)])\n",
        "        if self.unaligned:\n",
        "            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)])\n",
        "        else:\n",
        "            image_B = Image.open(self.files_B[index % len(self.files_B)])\n",
        "\n",
        "        if image_A.mode != \"RGB\":\n",
        "            image_A = to_rgb(image_A)\n",
        "        if image_B.mode != \"RGB\":\n",
        "            image_B = to_rgb(image_B)\n",
        "\n",
        "        item_A = self.transform(image_A)\n",
        "        item_B = self.transform(image_B)\n",
        "        return {\"A\": item_A, \"B\": item_B}\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ8adjM9D3VD"
      },
      "source": [
        "#### 2. Generator & Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjgaYezED3VE"
      },
      "outputs": [],
      "source": [
        "# 가중치 관련 함수 정의\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        if hasattr(m, \"bias\") and m.bias is not None:\n",
        "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPgCU8CiD3VE"
      },
      "outputs": [],
      "source": [
        "# Generator 내 ResidualBlock 관련 class 정의\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUU_6ZSRD3VF"
      },
      "outputs": [],
      "source": [
        "# generator 관련 class 정의\n",
        "\n",
        "class GeneratorResNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_residual_blocks):\n",
        "        super(GeneratorResNet, self).__init__()\n",
        "\n",
        "        channels = input_shape[0]\n",
        "\n",
        "        # Initial convolution block\n",
        "        out_features = 64\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(channels),\n",
        "            nn.Conv2d(channels, out_features, 7),\n",
        "            nn.InstanceNorm2d(out_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        in_features = out_features\n",
        "\n",
        "        # Downsampling\n",
        "        for _ in range(3):\n",
        "            out_features *= 2\n",
        "            model += [\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(num_residual_blocks):\n",
        "            model += [ResidualBlock(out_features)]\n",
        "\n",
        "        # Upsampling\n",
        "        for _ in range(3):\n",
        "            out_features //= 2\n",
        "            model += [\n",
        "                nn.Upsample(scale_factor=2),\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_features = out_features\n",
        "\n",
        "        # Output layer\n",
        "        model += [nn.ReflectionPad2d(channels), nn.Conv2d(out_features, channels, 7), nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q867yZJcD3VF"
      },
      "outputs": [],
      "source": [
        "# Discriminator 관련 class 정의\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        channels, height, width = input_shape\n",
        "\n",
        "        # Calculate output shape of image discriminator (PatchGAN)\n",
        "        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
        "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(channels, 64, normalize=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTg5cZT7D3VG"
      },
      "source": [
        "## 3. Training 관련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO8ObvwLELu9"
      },
      "outputs": [],
      "source": [
        "\n",
        "pretrained_model_path = \"/content/gdrive/MyDrive/python/data/Dataset/saved_models/sel2cha\"\n",
        "# epoch to start training from \n",
        "epoch_start = 0\n",
        "dataset_name=\"sel2cha\" #여기서 폴더가 지정되어 있어서 dataset안에 oldtonew폴더를 생성해야한다.\n",
        "channels = 3  #흑백의 경우 1 /RGB이미지는 3\n",
        "img_height = 256 \n",
        "img_width = 256 #가로세로크기 / 크기를 키울경우 cuda 메모리 오류가 생긴다.\n",
        "n_residual_blocks=9 #Generator에서의 Residual Block의 개수\n",
        "lr=0.0002 #learning rate\n",
        "b1=0.5 \n",
        "b2=0.999  #b1과 b2는 Adam opimizer에 대한 Hyper Parameter\n",
        "n_epochs=250 #목표200/ 했다가 비슷한 이미지가 생성되는 것을 확인하여 다른 방법이 필요하다고 느낌 or 에폭을 더 늘려보기\n",
        "init_epoch=0\n",
        "decay_epoch=25 #목표 100 /학습속도를 조절 처음에는 크게 그담에는 작은 단위로\n",
        "lambda_cyc=10.0\n",
        "lambda_id=5.0 #cycle-consistency loss 와 identity loss에 대한 람다값(id가 클수록 본래 색감 유지)\n",
        "n_cpu=8\n",
        "batch_size=1\n",
        "sample_interval=100\n",
        "checkpoint_interval= 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPMhxfYID3VG"
      },
      "outputs": [],
      "source": [
        "# 생성 이미지 및 모델 저장 폴더 생성\n",
        "\n",
        "os.makedirs(\"images/%s\" % dataset_name, exist_ok=True)\n",
        "os.makedirs(\"saved_models/%s\" % dataset_name, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZJYfgTfD3VG"
      },
      "outputs": [],
      "source": [
        "# Loss 값 정의\n",
        "\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61O_n58oD3VH"
      },
      "outputs": [],
      "source": [
        "# Generator, Discriminator 생성\n",
        "\n",
        "input_shape = (channels, img_height, img_width)\n",
        "\n",
        "G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n",
        "G_BA = GeneratorResNet(input_shape, n_residual_blocks)\n",
        "D_A = Discriminator(input_shape)\n",
        "D_B = Discriminator(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTZ0SzttD3VH"
      },
      "outputs": [],
      "source": [
        "# cuda 사용\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "if cuda:\n",
        "    G_AB = G_AB.cuda()\n",
        "    G_BA = G_BA.cuda()\n",
        "    D_A = D_A.cuda()\n",
        "    D_B = D_B.cuda()\n",
        "    criterion_GAN.cuda()\n",
        "    criterion_cycle.cuda()\n",
        "    criterion_identity.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA3RQHgID3VH"
      },
      "outputs": [],
      "source": [
        "if epoch_start != 0:\n",
        "    # Load pretrained models \n",
        "    G_AB.load_state_dict(torch.load(f\"{pretrained_model_path}/G_AB_195.pth\")) #런타임 오류로 끊길 우려가 있어서 중간에 가중치를 로드받아서 진행하는 모델 생성\n",
        "    G_BA.load_state_dict(torch.load(f\"{pretrained_model_path}/G_BA_195.pth\"))\n",
        "    D_A.load_state_dict(torch.load(f\"{pretrained_model_path}/D_A_195.pth\"))\n",
        "    D_B.load_state_dict(torch.load(f\"{pretrained_model_path}/D_B_195.pth\"))\n",
        "  \n",
        "\n",
        "\n",
        "# Initialize weights\n",
        "else : \n",
        "    G_AB.apply(weights_init_normal)    # old=>new generator 가중치 초기화\n",
        "    G_BA.apply(weights_init_normal)    # new=>old generator 가중치 초기화\n",
        "    D_A.apply(weights_init_normal)    # old discriminator 가중치 초기화\n",
        "    D_B.apply(weights_init_normal)    # new discriminator 가중치 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0zvlioCD3VI"
      },
      "outputs": [],
      "source": [
        "# Optimizer 정의\n",
        "\n",
        "optimizer_G = torch.optim.Adam(\n",
        "    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1, b2)\n",
        ")\n",
        "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr, betas=(b1, b2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U9L9uZ1D3VI"
      },
      "outputs": [],
      "source": [
        "# Learning Rate의 Decay 관련 class 정의\n",
        "\n",
        "class LambdaLR:\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        assert (n_epochs - decay_start_epoch) > 0, \"Decay must start before the training session ends!\"\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsrlaUo6D3VI"
      },
      "outputs": [],
      "source": [
        "# 학습률 조정\n",
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_G, lr_lambda=LambdaLR(n_epochs, init_epoch, decay_epoch).step\n",
        ")\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_D_A, lr_lambda=LambdaLR(n_epochs, init_epoch, decay_epoch).step\n",
        ")\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_D_B, lr_lambda=LambdaLR(n_epochs, init_epoch, decay_epoch).step\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4I11N0rD3VI"
      },
      "outputs": [],
      "source": [
        "# 이미지 임시 저장 관련 class 정의\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, max_size=50):\n",
        "        assert max_size > 0, \"Empty buffer or trying to create a black hole. Be careful.\"\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.uniform(0, 1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size - 1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return Variable(torch.cat(to_return))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RyeqcUnD3VJ"
      },
      "outputs": [],
      "source": [
        "# 이전 생성 이미지들의 버퍼\n",
        "\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jtb49OdJKoW2"
      },
      "outputs": [],
      "source": [
        "# 텐서 연산에 사용할 Tensor 자료형을 정의합니다.\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v-VyMpUD3VJ",
        "outputId": "83b51d0a-da13-4590-d960-386d7913072f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        }
      ],
      "source": [
        "# 이미지 transformation 정보\n",
        "\n",
        "transforms_ = [\n",
        "    transforms.Resize(int(img_height * 1.12), Image.BICUBIC),\n",
        "    transforms.RandomCrop((img_height, img_width)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwreXd2Mg6Xd"
      },
      "source": [
        "## 4. Train 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJV7MhIkD3VJ",
        "outputId": "18b5017d-f0ae-4ede-ae23-8c209e69bb1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "# Train DataSet 생성\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    ImageDataset(\"./images/%s\" % dataset_name, transforms_=transforms_, unaligned=True),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=n_cpu,\n",
        ")\n",
        "\n",
        "\n",
        "# Test DataSet 생성\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    ImageDataset(\"./images/%s\" % dataset_name, transforms_=transforms_, unaligned=True, mode=\"test\"),\n",
        "    batch_size=5,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9OxVOLUD3VJ"
      },
      "outputs": [],
      "source": [
        "# 이미지 저장 함수 정의\n",
        "\n",
        "def sample_images(batches_done):\n",
        "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
        "    imgs = next(iter(val_dataloader))\n",
        "    G_AB.eval()\n",
        "    G_BA.eval()\n",
        "    real_A = Variable(imgs[\"A\"].type(Tensor))\n",
        "    fake_B = G_AB(real_A)\n",
        "    \n",
        "    # Arange images along x-axis\n",
        "    real_A = make_grid(real_A, nrow=5, normalize=True)\n",
        "    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n",
        "    # Arange images along y-axis\n",
        "    image_grid = torch.cat((real_A, fake_B), 1)\n",
        "    save_image(image_grid, \"images/%s/%s.png\" % (dataset_name, batches_done), normalize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0_NWkWID3VJ",
        "outputId": "270502b0-4747-4c93-d9e8-2e30ac9f17c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 110/250] [Batch 484/500] [D loss: 0.097119] [G loss: 1.594079, adv: 0.591964, cycle: 0.078746, identity: 0.042932] ETA: 14:40:26.225879"
          ]
        }
      ],
      "source": [
        "prev_time = time.time()\n",
        "\n",
        "loss_d_hist = np.empty\n",
        "loss_g_hist = np.empty\n",
        "loss_gan_hist = np.empty\n",
        "loss_cycle_hist = np.empty\n",
        "loss_identity_hist = np.empty\n",
        "\n",
        "for epoch in range(epoch_start, n_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "\n",
        "        # (1) Set model input\n",
        "        real_A = Variable(batch[\"A\"].type(Tensor))\n",
        "        real_B = Variable(batch[\"B\"].type(Tensor))\n",
        "\n",
        "\n",
        "        # (2) Adversarial ground truths\n",
        "        valid = Variable(Tensor(np.ones((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n",
        "        fake = Variable(Tensor(np.zeros((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n",
        "\n",
        "\n",
        "        # (3) Train Generators\n",
        "        G_AB.train()\n",
        "        G_BA.train()\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "\n",
        "        # (4) Identity loss : 색감, 형태 등을 유지하기 위한 값\n",
        "        loss_id_A = criterion_identity(G_BA(real_A), real_A)\n",
        "        loss_id_B = criterion_identity(G_AB(real_B), real_B)\n",
        "        loss_identity = (loss_id_A + loss_id_B) / 2\n",
        "\n",
        "\n",
        "        # (5) GAN loss\n",
        "        fake_B = G_AB(real_A)\n",
        "        loss_GAN_AB = criterion_GAN(D_B(fake_B), valid)\n",
        "        fake_A = G_BA(real_B)\n",
        "        loss_GAN_BA = criterion_GAN(D_A(fake_A), valid)\n",
        "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
        "\n",
        "\n",
        "        # (6) Cycle loss\n",
        "        recov_A = G_BA(fake_B)\n",
        "        loss_cycle_A = criterion_cycle(recov_A, real_A)\n",
        "        recov_B = G_AB(fake_A)\n",
        "        loss_cycle_B = criterion_cycle(recov_B, real_B)\n",
        "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
        "\n",
        "\n",
        "        # (7) Total loss\n",
        "        loss_G = loss_GAN + lambda_cyc * loss_cycle + lambda_id * loss_identity\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "\n",
        "        # (8) Train Discriminator A\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "\n",
        "        # (9) Real loss\n",
        "        loss_real = criterion_GAN(D_A(real_A), valid)\n",
        "\n",
        "\n",
        "        # (10) Fake loss (on batch of previously generated samples)\n",
        "        fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n",
        "        loss_fake = criterion_GAN(D_A(fake_A_.detach()), fake)\n",
        "        \n",
        "\n",
        "        # (11) Total loss\n",
        "        loss_D_A = (loss_real + loss_fake) / 2\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "\n",
        "        # (12) Train Discriminator B\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "\n",
        "        # (13) Real loss\n",
        "        loss_real = criterion_GAN(D_B(real_B), valid)\n",
        "\n",
        "\n",
        "        # (14) Fake loss (on batch of previously generated samples)\n",
        "        fake_B_ = fake_B_buffer.push_and_pop(fake_B)\n",
        "        loss_fake = criterion_GAN(D_B(fake_B_.detach()), fake)\n",
        "\n",
        "\n",
        "        # (15) Total loss\n",
        "        loss_D_B = (loss_real + loss_fake) / 2\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "        loss_D = (loss_D_A + loss_D_B) / 2\n",
        "\n",
        "\n",
        "        # (16) Determine approximate time left\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        batches_left = n_epochs * len(dataloader) - batches_done\n",
        "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
        "        prev_time = time.time()\n",
        "\n",
        "\n",
        "        # (17) Print log\n",
        "        sys.stdout.write(\n",
        "            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] ETA: %s\"\n",
        "            % (\n",
        "                epoch,\n",
        "                n_epochs,\n",
        "                i,\n",
        "                len(dataloader),\n",
        "                loss_D.item(),\n",
        "                loss_G.item(),\n",
        "                loss_GAN.item(),\n",
        "                loss_cycle.item(),\n",
        "                loss_identity.item(),\n",
        "                time_left,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        \n",
        "        # (18) If at sample interval save image and save loss history\n",
        "        if batches_done % sample_interval == 0:\n",
        "            sample_images(batches_done)\n",
        "            loss_d_hist = np.append(loss_d_hist, loss_D.item())\n",
        "            loss_g_hist = np.append(loss_g_hist, loss_G.item())\n",
        "            loss_gan_hist = np.append(loss_gan_hist, loss_GAN.item())\n",
        "            loss_cycle_hist = np.append(loss_cycle_hist, loss_cycle.item())\n",
        "            loss_identity_hist = np.append(loss_identity_hist, loss_identity.item())\n",
        "\n",
        "\n",
        "    # (19) Update learning rates\n",
        "    lr_scheduler_G.step()\n",
        "    lr_scheduler_D_A.step()\n",
        "    lr_scheduler_D_B.step()\n",
        "\n",
        "\n",
        "    # (20) Save model checkpoints\n",
        "    if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:\n",
        "        torch.save(G_AB.state_dict(), \"saved_models/%s/G_AB_%d.pth\" % (dataset_name, epoch))\n",
        "        torch.save(G_BA.state_dict(), \"saved_models/%s/G_BA_%d.pth\" % (dataset_name, epoch))\n",
        "        torch.save(D_A.state_dict(), \"saved_models/%s/D_A_%d.pth\" % (dataset_name, epoch))\n",
        "        torch.save(D_B.state_dict(), \"saved_models/%s/D_B_%d.pth\" % (dataset_name, epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RlWXQOqY9fu"
      },
      "source": [
        "## 3. Train Loss 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG2zjDj4XqUE"
      },
      "outputs": [],
      "source": [
        "# 시각화 라이브러리 임포트\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-_4qwE1Y538"
      },
      "outputs": [],
      "source": [
        "x = range(len(loss_d_hist[1:]))\n",
        "\n",
        "loss_d_hist = loss_d_hist[1:]\n",
        "loss_g_hist = loss_g_hist[1:]\n",
        "loss_gan_hist = loss_gan_hist[1:]\n",
        "loss_cycle_hist = loss_cycle_hist[1:]\n",
        "loss_identity_hist = loss_identity_hist[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6Wtfd1cYoeQ"
      },
      "outputs": [],
      "source": [
        "# Discriminator loss 관련 시각화\n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "ax = fig.add_subplot()\n",
        "ax.plot(x, loss_d_hist, color = 'gray')\n",
        "plt.xlabel('step_100', fontsize=14)\n",
        "plt.ylabel('loss', fontsize=14)\n",
        "plt.legend(['Discriminator'], fontsize=12, loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwuPXAStmUji"
      },
      "outputs": [],
      "source": [
        "print('최소 loss 값 : ' + str(loss_d_hist.min()))\n",
        "print('최소 loss 값 step : ' + str(int(np.where(loss_d_hist == loss_d_hist.min())[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpVSs7QfXliz"
      },
      "outputs": [],
      "source": [
        "# Generator loss 관련 시각화\n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "ax = fig.add_subplot()\n",
        "ax.plot(x, loss_g_hist)\n",
        "ax.plot(x, loss_gan_hist, linewidth = '0.5')\n",
        "ax.plot(x, loss_cycle_hist, linewidth = '0.5')\n",
        "ax.plot(x, loss_identity_hist, linewidth = '0.5')\n",
        "plt.xlabel('step_100', fontsize=14)\n",
        "plt.ylabel('loss', fontsize=14)\n",
        "plt.legend(['Generator', 'GAN', 'cycle', 'identity'], fontsize=12, loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lv-LijKpOyf"
      },
      "outputs": [],
      "source": [
        "print('최소 loss 값 : ' + str(loss_g_hist.min()))\n",
        "print('최소 loss 값 step : ' + str(int(np.where(loss_g_hist == loss_g_hist.min())[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6yRsbDIrlk9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "sel2cha.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
